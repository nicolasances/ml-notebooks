{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ce3429-51e5-47ca-b08b-e772154ad2ff",
   "metadata": {},
   "source": [
    "# Supermarket Items Order Model\n",
    "\n",
    "This notebook is used as an experimentation notebook to train a model that sorts items in a supermarket list in the most optimal pick-up order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69a8a4-6f12-486a-abf2-2b5785a472a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"eu-west-1\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Input, Flatten, Concatenate, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import uniform, randint, boxcox\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Load the data\n",
    "archived_lists = pd.read_json('/home/sagemaker-user/ml-notebooks/toto/supermarket/item-order/20241025-archivedLists.json')\n",
    "game_examples = pd.read_json('/home/sagemaker-user/ml-notebooks/toto/supermarket/item-order/20241025-trainingExamples.json')\n",
    "\n",
    "# Basic variables that are going to be used later\n",
    "target_var = 'before'\n",
    "id_var = '_id'\n",
    "\n",
    "archived_lists.drop(columns=[id_var], inplace=True)\n",
    "game_examples.drop(columns=[id_var], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a99ac3-68eb-4bd3-9a97-f1d06a98ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "archived_lists.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae39ab-79ff-4a7a-a67c-fc0461320600",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_examples.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b29055-0a40-45d9-9f7c-721367752e66",
   "metadata": {},
   "source": [
    "---\n",
    "# Bedrock Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d763b9-3b98-41ef-90a1-e79f932951c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama:\n",
    "\n",
    "    model_id = \"eu.meta.llama3-2-3b-instruct-v1:0\"\n",
    "\n",
    "    def invoke(self, prompt: str): \n",
    "        \n",
    "        formatted_prompt = f\"\"\"\n",
    "        <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "        {prompt}\n",
    "        <|eot_id|>\n",
    "        <|start_header_id|>assistant<|end_header_id|>\n",
    "        \"\"\"\n",
    "        \n",
    "        native_request = {\n",
    "            \"prompt\": formatted_prompt,\n",
    "            \"max_gen_len\": 2000,\n",
    "            \"temperature\": 0,\n",
    "        }\n",
    "        \n",
    "        # Convert the native request to JSON.\n",
    "        request = json.dumps(native_request)\n",
    "        \n",
    "        try:\n",
    "            # Invoke the model with the request.\n",
    "            response = client.invoke_model(modelId=self.model_id, body=request)\n",
    "        \n",
    "            # Decode the response body.\n",
    "            model_response = json.loads(response[\"body\"].read())\n",
    "            \n",
    "            # Extract and print the response text.\n",
    "            response_text = model_response[\"generation\"]\n",
    "            \n",
    "            return response_text\n",
    "        \n",
    "        except (ClientError, Exception) as e:\n",
    "            print(f\"ERROR: Can't invoke '{self.model_id}'. Reason: {e}\")\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8117f5-2684-4579-b1d8-f9e54af59d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Claude: \n",
    "\n",
    "    model_id = 'eu.anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "    def invoke(self, prompt: str): \n",
    "        # Start a conversation with the user message.\n",
    "        \n",
    "        conversation = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"text\": prompt}],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            # Send the message to the model, using a basic inference configuration.\n",
    "            response = client.converse(\n",
    "                modelId=self.model_id,\n",
    "                messages=conversation,\n",
    "                inferenceConfig={\"maxTokens\": 2000, \"temperature\": 0, \"topP\": 0.9},\n",
    "            )\n",
    "        \n",
    "            # Extract and print the response text.\n",
    "            return response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "        \n",
    "        except (ClientError, Exception) as e:\n",
    "            print(f\"ERROR: Can't invoke '{self.model_id}'. Reason: {e}\")\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f02cf7-48cf-4a5e-93b4-0687293dd1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "\n",
    "class ItemClassifier:\n",
    "\n",
    "    categories = {\n",
    "        'Produce': ['apples', 'bananas', 'lettuce', 'tomatoes', 'sweet potato', 'carrots'],\n",
    "        'Dairy': ['milk', 'cheese', 'yogurt', 'butter', 'mozzarella', 'ricotta'],\n",
    "        'Bakery': ['bread', 'bagels', 'muffins', 'cakes', 'wasa'],\n",
    "        'Meat': ['chicken', 'beef', 'pork', 'sausage', 'medister', 'bacon'],\n",
    "        'Seafood': ['salmon', 'tuna', 'shrimp', 'cod'],\n",
    "        'Frozen Foods': ['ice cream', 'frozen pizza', 'frozen vegetables', 'frozen bread'],\n",
    "        'Canned Goods': ['soup', 'beans', 'corn', 'tomato sauce'],\n",
    "        'Pasta and Rice': ['spaghetti', 'penne', 'rice', 'couscous'],\n",
    "        'Condiments and Sauces': ['ketchup', 'mustard', 'mayo', 'salad dressing'],\n",
    "        'Oils and Vinegars': ['olive oil', 'vegetable oil', 'balsamic vinegar'],\n",
    "        'Snacks': ['chips', 'pretzels', 'popcorn', 'nuts'],\n",
    "        'Breakfast Foods': ['cereal', 'oatmeal', 'musli', 'pancake mix'],\n",
    "        'Beverages': ['soda', 'juice', 'water', 'coffee', 'havremælk'],\n",
    "        'Baking Supplies': ['flour', 'sugar', 'baking powder', 'vanilla extract'],\n",
    "        'Spreads': ['jam', 'honey', 'peanut butter', 'nutella'],\n",
    "        'Pet Supplies': ['dog food', 'cat litter', 'pet toys', 'dog bags'],\n",
    "        'Personal Care': ['shampoo', 'soap', 'toothpaste', 'deodorant'],\n",
    "        'Household Items': ['paper towels', 'toilet paper', 'trash bags', 'diapers'],\n",
    "        'Deli': ['sliced meats', 'olives', 'hummus', 'prepared salads'],\n",
    "        'International Foods': ['salsa', 'soy sauce', 'curry paste', 'tortillas']\n",
    "    }\n",
    "\n",
    "    def categorize(self, item: str):\n",
    "    \n",
    "        prompt = f\"\"\"\n",
    "        The following are supermarket items' categories. Each category has some examples of typical items that would belong in that category. \n",
    "        ---\n",
    "        CATEGORIES:\n",
    "        {self.categories}\n",
    "        ---\n",
    "        \n",
    "        I need you to pick the most probable category for the following item: '{item}'.\n",
    "        You can only consider categories that are among the ones that I provided above. \n",
    "        \n",
    "        If you cannot assign a category, return the category 'unknown'.\n",
    "\n",
    "        Only return the name of the category. Nothing else. \n",
    "        \"\"\"\n",
    "        \n",
    "        return Claude().invoke(prompt)\n",
    "\n",
    "    def batch_categorize(self, items, return_as: str = None): \n",
    "\n",
    "        instructions = \"\"\"\n",
    "        For each item, return a tuple in this format: \n",
    "        (item, category)\n",
    "        'category' must be a string \n",
    "        'item' must be the item name\n",
    "\n",
    "        Do not return any text expect the list of tuples. The list of tuples must be formatted as follows: \n",
    "        [tuple1, tuple2, ...]\n",
    "        \"\"\"\n",
    "\n",
    "        if return_as == 'array': \n",
    "            instructions = \"\"\"\n",
    "            Return the categories as a list. \n",
    "            Do not return any text expect the list of categories, which must be formatted as follows: \n",
    "            ['category1', 'category2', ...]\n",
    "            \"\"\"\n",
    "        elif return_as == 'dict': \n",
    "            instructions = \"\"\"\n",
    "            Return the categories as a dict in this format: \n",
    "            {'item1': 'category_of_item1', 'item2': 'category_of_item2', ...}\n",
    "\n",
    "            Do not return any text expect the dict as specified above. \n",
    "            \"\"\"\n",
    "\n",
    "        items_string = \", \".join(items)\n",
    "    \n",
    "        prompt = f\"\"\"\n",
    "        The following are supermarket items' categories. Each category has some examples of typical items that would belong in that category. \n",
    "        ---\n",
    "        CATEGORIES:\n",
    "        {self.categories}\n",
    "        ---\n",
    "        \n",
    "        I need you to pick the most probable category for the following items.\n",
    "        ---\n",
    "        ITEMS:\n",
    "        [{items_string}].\n",
    "        ---\n",
    "        You can only consider categories that are among the ones that I provided above. \n",
    "        \n",
    "        If you cannot assign a category, return the category 'unknown'.\n",
    "\n",
    "        {instructions}\n",
    "        \"\"\"\n",
    "        \n",
    "        result = Claude().invoke(prompt)\n",
    "\n",
    "        \n",
    "        if return_as == 'array' or return_as == 'dict': \n",
    "            return ast.literal_eval(result)\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f2364-cff7-42b9-a498-3ade105e2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemClassifier().categorize('eggs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b54c6-0ba4-4a61-98e0-ef5e0d1b6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemClassifier().batch_categorize(['eggs', 'nutella', 'peanut butter', 'letmælk', 'latte', 'medister', 'bacon i tern', 'bacon', 'pesto'], return_as='dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a27c4-cd38-47f9-973e-972847ff8a62",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Preparation & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedde32c-2743-466f-8840-e7ee3b51275e",
   "metadata": {},
   "source": [
    "## Uniforming Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf836b-7368-4579-82b5-385f5292505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_archived_lists_to_examples(dataset):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for list_id, group in dataset.groupby(\"listId\"):\n",
    "        # Sort the group by userIndex to get the pickup order\n",
    "        sorted_group = group.sort_values(\"userIndex\")\n",
    "    \n",
    "        # Get all possible pairs of items in the sorted order\n",
    "        for (i, row1), (j, row2) in combinations(sorted_group.iterrows(), 2):\n",
    "            \n",
    "            item1, item2 = row1[\"name\"], row2[\"name\"]\n",
    "            supermarket_id = row1[\"supermarketId\"]\n",
    "            \n",
    "            # Determine if item1 was picked \"before\" or \"after\" item2 based on userIndex\n",
    "            if row1[\"userIndex\"] < row2[\"userIndex\"]:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "    \n",
    "            # Append the result as a new row\n",
    "            results.append({\n",
    "                \"item1\": item1,\n",
    "                \"item2\": item2,\n",
    "                \"before\": label,\n",
    "                \"supermarket_id\": supermarket_id, \n",
    "                # 'list_id': list_id\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc28d8-fe18-4b7e-ab71-701d21e40869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_game_examples(dataset): \n",
    "\n",
    "    df = dataset.copy()\n",
    "\n",
    "    df['before'] = df['label'].apply(lambda label: 1 if label == 'before' else 0)\n",
    "    df['supermarket_id'] = df['supermarketId']\n",
    "    df.drop(columns=['supermarketId', 'label', 'date'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a541a-2310-434e-aa08-20f9491f6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_and_balance_training_examples(archived_lists=archived_lists, game_examples=game_examples): \n",
    "    \n",
    "    # 1. Convert the archived lists to pairs of training examples\n",
    "    ex1 = convert_archived_lists_to_examples(archived_lists)\n",
    "\n",
    "    # 2. Prepare the game examples\n",
    "    ex2 = prepare_game_examples(game_examples)\n",
    "\n",
    "    # 3. Unite the two\n",
    "    df = pd.concat([ex1, ex2], axis=0)\n",
    "\n",
    "    # 4. Rebalance the dataset: for each pair (item1, item2) with before = 1, generate one (item2, item1) with before = 0\n",
    "    # Otherwise I have an extremely unbalanced dataset\n",
    "    df_before = df[df[\"before\"] == 1]\n",
    "    df_swapped = df_before.copy()\n",
    "    df_swapped[\"item1\"], df_swapped[\"item2\"] = df_before[\"item2\"], df_before[\"item1\"]\n",
    "    df_swapped[\"before\"] = 0\n",
    "\n",
    "    # 5. Unite\n",
    "    return pd.concat([df, df_swapped], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e9fdc-6ecf-4bc9-baa2-ffbb775cbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unite_and_balance_training_examples()\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(df, x='before')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67913271-8409-4bff-8c09-3cc5f8983cf2",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53ae714-c4e5-4526-9c68-4cce71c35e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_useless_words(df):\n",
    "    \"\"\"Removes words that are considered useless (e.g. 'c', 'big', 'for', etc..)\n",
    "    \"\"\"\n",
    "    useless_words = ['c', 'n', 'noah', 'for', 'us', 'x2', 'big', 'pack', 'greek', 'or', 'something', 'caro',  'sweet', 'p', 'small']\n",
    "\n",
    "    # Define the cleaning function for each item1 value\n",
    "    def remove_useless_words(text):\n",
    "        \n",
    "        words = text.split()  \n",
    "        \n",
    "        # Filter out any words that are in the useless_words list\n",
    "        cleaned_words = [word for word in words if word.lower() not in useless_words]\n",
    "        \n",
    "        return ' '.join(cleaned_words)  # Join the remaining words back into a single string\n",
    "\n",
    "    df['item1'] = df['item1'].apply(remove_useless_words)\n",
    "    df['item2'] = df['item2'].apply(remove_useless_words)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd8318-0461-45d7-9ec4-f4989a2cc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_long_items(df):\n",
    "    # Filter rows where item1 or item2 has 3 or fewer words\n",
    "    df_filtered = df[df[\"item1\"].apply(lambda x: len(x.split()) < 3)]\n",
    "    df_filtered = df_filtered[df_filtered[\"item2\"].apply(lambda x: len(x.split()) < 3)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a536b06-5b10-45b5-8531-02c8c2c5de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_of_items(df):\n",
    "    df[\"item1\"] = df[\"item1\"].str.lower()\n",
    "    df[\"item2\"] = df[\"item2\"].str.lower()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430bc1b-9385-4f83-b427-590d0191b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    return lower_case_of_items(\n",
    "        remove_empty_rows(\n",
    "            remove_rows_with_long_items(\n",
    "                remove_useless_words(df)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b631d8-0865-4d9b-9e69-cf6c288279b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    return lower_case_of_items(\n",
    "        remove_empty_rows(\n",
    "            remove_rows_with_long_items(\n",
    "                remove_useless_words(df)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdb08e-7b3b-4689-8e43-a773453874ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean_data(df.copy())\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50346dee-0bff-430f-a0cb-6dbd0bc5cd39",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "We're only going to train a model on supermarket 1. There's not enough data in general on other supermarkets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e235e-b969-48e1-af1b-08d2062ffa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_supermarkets(df):\n",
    "    return df[df['supermarket_id'] == 1].drop(columns='supermarket_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c64b03-71cc-4bdf-9c1b-81dd0cbf1baa",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83583cc9-9121-488d-a45d-607bd3c2f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_dictionnary(df):\n",
    "    return pd.concat([pd.Series(df['item1']), pd.Series(df['item1'])]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0423701c-f74d-4549-bbb0-f6a03c9a0056",
   "metadata": {},
   "source": [
    "### Item Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a4914-5193-4e5c-8ca6-ecb9f9da4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_cat_dict(df):\n",
    "    return ItemClassifier().batch_categorize(get_items_dictionnary(df), return_as='dict')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45455f3-decc-47f9-a05b-377c78525282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_items_category(dataset):\n",
    "\n",
    "    df = dataset.copy()\n",
    "    \n",
    "    items_cat_dict = get_items_cat_dict(df)\n",
    "    \n",
    "    df['item1_cat'] = df['item1'].apply(lambda x : items_cat_dict.get(x, 'other').lower())\n",
    "    df['item2_cat'] = df['item2'].apply(lambda x : items_cat_dict.get(x, 'other').lower())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bbbea-0133-40c1-ac33-84844e41ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(dataset): \n",
    "    return add_items_category(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23314544-bd7e-4979-b122-0221aef43d09",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560df57b-d66f-4520-9d12-115b63e7bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_items(df, trained_encoders = None):\n",
    "    \n",
    "    items_dict = get_items_dictionnary(df)\n",
    "    items_cat_dict = get_items_cat_dict(df)\n",
    "    item_categories = list(items_cat_dict.keys())\n",
    "\n",
    "    if trained_encoders is None: \n",
    "        item_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        cat_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        \n",
    "        item_encoder.fit(items_dict.reshape(-1,1))\n",
    "        cat_encoder.fit(np.array(item_categories).reshape(-1,1))\n",
    "    else:\n",
    "        item_encoder = trained_encoders['item_encoder']\n",
    "        cat_encoder = trained_encoders['cat_encoder']\n",
    "\n",
    "    encoded_df = df.copy()\n",
    "    \n",
    "    encoded_item1 = pd.DataFrame(item_encoder.transform(df[['item1']]), columns=items_dict).add_prefix('item1_')\n",
    "    encoded_item2 = pd.DataFrame(item_encoder.transform(df[['item2']]), columns=items_dict).add_prefix('item2_')\n",
    "    encoded_cat1 = pd.DataFrame(item_encoder.transform(df[['item1_cat']]), columns=item_categories).add_prefix('cat1_')\n",
    "    encoded_cat2 = pd.DataFrame(item_encoder.transform(df[['item2_cat']]), columns=item_categories).add_prefix('cat2_')\n",
    "    \n",
    "    encoded_df.drop(columns=['item1', 'item2', 'item1_cat', 'item2_cat'], inplace=True)\n",
    "\n",
    "    encoded_df = pd.concat([encoded_df, encoded_item1, encoded_item2, encoded_cat1, encoded_cat2], axis=1)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": encoded_df, \n",
    "        \"item_encoder\": item_encoder, \n",
    "        \"cat_encoder\": cat_encoder\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ef0c5-78fe-4ab2-83a3-99aa7782b6b7",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec9539c-534f-4c2b-b5bb-470a3a07b5ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filter_supermarkets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Get the dataset without encoding\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m eda_df \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_supermarkets\u001b[49m(\n\u001b[1;32m      3\u001b[0m                 clean_data(\n\u001b[1;32m      4\u001b[0m                     unite_and_balance_training_examples()\n\u001b[1;32m      5\u001b[0m                 )\n\u001b[1;32m      6\u001b[0m             )\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      9\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(eda_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filter_supermarkets' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Get the dataset without encoding\n",
    "eda_df = filter_supermarkets(\n",
    "                clean_data(\n",
    "                    unite_and_balance_training_examples()\n",
    "                )\n",
    "            )\n",
    "\n",
    "plt.figure(figsize=(25, 4))\n",
    "sns.countplot(eda_df, x='item1')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7220da-8ea4-4ff6-92da-405a17caeaaa",
   "metadata": {},
   "source": [
    "\n",
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd51a73-0140-4289-bff5-911a6396553b",
   "metadata": {},
   "source": [
    "## Common Training functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef0c298-426a-403a-82a2-9282ac722fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name=\"Unamed Model\", prepared_data=None):\n",
    "\n",
    "    # 1. Prepare the data for Training\n",
    "    if prepared_data is None: \n",
    "        preparation_result = encode_items(\n",
    "            engineer_features(\n",
    "                filter_supermarkets(\n",
    "                    clean_data(\n",
    "                        unite_and_balance_training_examples()\n",
    "                    )\n",
    "                )   \n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        preparation_result = prepared_data\n",
    "\n",
    "    dataset = preparation_result['dataset']\n",
    "\n",
    "    # 2. Split the data \n",
    "    X = dataset.drop(columns=[target_var]).to_numpy()\n",
    "    y = dataset[target_var].to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=32)\n",
    "\n",
    "    # 3. Fit\n",
    "    print(f\"\\nFitting {model_name}\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. Score\n",
    "    y_train_pred = model.predict_proba(X_train)[:,1]\n",
    "    y_test_pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    scores = {\n",
    "        'train': roc_auc_score(y_train, y_train_pred),\n",
    "        'test': roc_auc_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name}: Train Score [{scores['train']}] - Test Score [{scores['test']}]\")\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'scores': scores, \n",
    "        'item_encoder': preparation_result['item_encoder']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93331a26-acf9-4161-a02f-2564eee4f940",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engineer_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prepared_data \u001b[38;5;241m=\u001b[39m encode_items(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mengineer_features\u001b[49m(\n\u001b[1;32m      3\u001b[0m         filter_supermarkets(\n\u001b[1;32m      4\u001b[0m             clean_data(\n\u001b[1;32m      5\u001b[0m                 unite_and_balance_training_examples()\n\u001b[1;32m      6\u001b[0m             )\n\u001b[1;32m      7\u001b[0m         )   \n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrepared Data Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprepared_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engineer_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "prepared_data = encode_items(\n",
    "    engineer_features(\n",
    "        filter_supermarkets(\n",
    "            clean_data(\n",
    "                unite_and_balance_training_examples()\n",
    "            )\n",
    "        )   \n",
    "    )\n",
    ")\n",
    "print(f\"Prepared Data Shape: {prepared_data['dataset'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3425a494-6db1-4eb9-9374-8abba0863b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = train_model(RandomForestClassifier(), model_name=\"Random Forest\", prepared_data=prepared_data)\n",
    "xgb_model = train_model(XGBClassifier(), model_name=\"XGBoost\", prepared_data=prepared_data)\n",
    "cat_boost_model = train_model(CatBoostClassifier(verbose=0), model_name=\"Cat Boost\", prepared_data=prepared_data)\n",
    "lgbm_model = train_model(LGBMClassifier(verbose=-1), model_name=\"Light GBM\", prepared_data=prepared_data)\n",
    "mlp_model = train_model(MLPClassifier(), model_name=\"MLP\", prepared_data=prepared_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86e002-2416-4b71-8a3a-cd3aa0c4154a",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223dc3d-518b-4f66-817a-d02ce95f8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlp_grid_search(prepared_data=None):\n",
    "\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(256, 256), (128, 128, 128, 128)],\n",
    "        'activation': ['relu'],\n",
    "        'alpha': [1.0, 3.0]\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=500)\n",
    "\n",
    "    gs = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='roc_auc', cv=3, n_jobs=-1)\n",
    "    \n",
    "    result = train_model(gs, model_name=\"Grid Search MLP\", prepared_data=prepared_data)\n",
    "\n",
    "    print(\"Best parameters found: \", gs.best_params_)\n",
    "    print(\"Best score: \", gs.best_score_)\n",
    "\n",
    "    result['model'] = gs.best_estimator_\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465226ed-c0af-49ba-8a87-86e4420ee8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_best = mlp_grid_search(prepared_data=prepared_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a9fcc-2042-4a5f-a61b-cdd03ae43b6d",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "The best trained model of the first version of this model, obtained without considering Item Categories was: <br>\n",
    "Train Score [0.8328987977864004] - Test Score [**0.7889**227377472335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26ca57-f437-489d-af9e-9d3d2ed53045",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = train_model(MLPClassifier(alpha=1.0, hidden_layer_sizes=(20,20)), model_name=\"Chosen Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fd2794-ae0f-4ed5-8261-dc6ba060e257",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69deab56-c6df-4b26-bc37-38da4b94d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['bread', 'jam']\n",
    "example_df = pd.DataFrame([example], columns=['item1', 'item2'])\n",
    "\n",
    "encoded_example = encode_items(example_df, encoder=final_model['item_encoder'])['dataset']\n",
    "\n",
    "predicted_before = final_model['model'].predict_proba(encoded_example)[:,1]\n",
    "\n",
    "print(f\"Probability that '{example[0]}' comes before '{example[1]}': {predicted_before[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
