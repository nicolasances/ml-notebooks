{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98947b22-7988-42e1-b0c6-8285a6b4f04d",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69869bd4-2fad-4fc1-a5ff-045f1dc4779a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seabornborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7993/4089981614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseabornborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seabornborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seabornborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc198129-4593-47d8-9700-0789b838a25f",
   "metadata": {},
   "source": [
    "## Training Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883a30e-5154-48d2-9038-228d3415eb81",
   "metadata": {},
   "source": [
    "The problem I'll use to try a NN is the same as a Logistic Regression problem: simple binary classification. <br>\n",
    "The following are training examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137bff0-428e-472c-bc21-52bf044dcd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = 30\n",
    "x1_train = [2, 0.8, 0.9, 0.95, 1.5, 1.6, 3, 2.8, 1, 1.4, 2.3, 3.4, 1.2, 0.5, 2, 2.1, 4.1, 5, 6, 4, 4.5, 5.3, 6.4, 6, 5.2, 5.3, 5.4, 6, 5.8, 6.1]\n",
    "x2_train = [1, 3, 4.2, 6, 5, 4, 2, 3.5, 1.1, 3, 2, 2.8, 2.1, 0.7, 2.6, 2.5, 7, 8, 6.5, 6, 6.5, 7.8, 8.4, 7.5, 5, 5.5, 4, 5, 6.2, 4.5]\n",
    "Y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]).reshape(1, len(x1_train))\n",
    "x0 = np.ones(len(x1_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febcc1aa-1cbc-4616-8b1e-c1b066db02dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Training examples: {m}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a2aa7-9aa4-4faf-b49b-f4ae60735240",
   "metadata": {},
   "source": [
    "The NN will need to correctly find the **decision boundary** for the problem plotted below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2a54b-1eb9-4a5e-8bdb-eae696b37c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x = x1_train, y = x2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82d4c8-622d-433e-886a-9f22df0fb9b7",
   "metadata": {},
   "source": [
    "---\n",
    "## Training the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1354183d-9aa9-4ff4-8e1f-68afb41c6ab0",
   "metadata": {},
   "source": [
    "Neural Networks's neurons are basically logistic regressors, that are **activated** based on the function, $h_{\\Theta}(x)$, defined as follows: \n",
    "$$ \n",
    "h_{\\Theta}(x) = \\frac{1}{1 + e^{-z(x)}}\n",
    "$$\n",
    "where $z(x)$ is any polynomial in a vector x, and can be defined as: \n",
    "$$\n",
    "z(X) = \\Theta X\n",
    "$$\n",
    "\n",
    "\n",
    "In this notebook, I'll build a NN with a **single hidden layer** of **two nodes** (plus the standard \"fixed term\" node). <br>\n",
    "For each neuron in the **hidden layer**, we calculate $z(X)$ as above, considering the following. <br>\n",
    "\n",
    "There will be in total 3 layers:\n",
    " 1. $A^0$, an $\\mathbb{R}^{3,m}$ matrix, which is the input layer $X$, composed of three nodes ($x_0, x_1, x_2$ where $x_0$ is a just 1) with $m$ training examples\n",
    " 2. $A^1$, an $\\mathbb{R}^{3,m}$ matrix, which is the hidden layer, composed of two nodes plus a fixed node (1), with $m$ training examples\n",
    " 3. $A^2$, an $\\mathbb{R}^{1,m}$ vector, which is the output layer, composed of a single node, with $m$ training example output\n",
    "\n",
    "That means that: \n",
    " * $X$ must be a **matrix** $\\mathbb{R}^{3,m}$ where each **row** is a feature ($x_0, x_1, x_2$) and each **column** is a training example. So training examples are organized in rows for each feature.\n",
    " * $\\Theta^{(0)}$ must be a **matrix** $\\mathbb{R}^{2, 3}$ \n",
    " * $\\Theta^{(1)}$ must be a **vector** $\\mathbb{R}^{1, 3}$. The $3$ comes from the fact that we add one node ($a_0$ with fixed value $1$) to the hidden layer \n",
    "\n",
    "$$\n",
    "\\Theta^{(0)}=\n",
    "\\begin{bmatrix}\n",
    "\\theta^{(0)}_{0,0} & \\theta^{(0)}_{0,1} & \\theta^{(0)}_{0,2} \\\\\n",
    "\\theta^{(0)}_{1,0} & \\theta^{(0)}_{1,1} & \\theta^{(0)}_{1,2}\n",
    "\\end{bmatrix}\n",
    "\\textrm{ and } \\Theta^{(1)}=\n",
    "\\begin{bmatrix}\n",
    "\\theta^{(1)}_{0,0} & \\theta^{(1)}_{0,1} & \\theta^{(0)}_{0,2}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\theta^{(0)}_{a, b}$ is the **weight** of the link between the input neuron $b$ and the output neuron (in this case hidden layer) $a$  \n",
    "\n",
    "That means that $\\Theta^{(0)}X$ is: \n",
    "$$ \n",
    "\\Theta^{(0)}X = \n",
    "\\begin{bmatrix}\n",
    "\\theta^{(0)}_{0,0} & \\theta^{(0)}_{0,1} & \\theta^{(0)}_{0,2} \\\\\n",
    "\\theta^{(0)}_{1,0} & \\theta^{(0)}_{1,1} & \\theta^{(0)}_{1,2}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_{0,0} & x_{0,1} & ... & x_{0,m - 1} \\\\\n",
    "x_{1,0} & x_{1,1} & ... & x_{1,m - 1} \\\\\n",
    "x_{2,0} & x_{2,1} & ... & x_{2,m - 1} \\\\\n",
    "\\end{bmatrix}\n",
    "=\\mathbb{R}^{2,m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e16ec92-1243-4c1f-884f-337eeaa85772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def z(A, Theta):\n",
    "    return np.matmul(Theta, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba5dc97-2183-44f2-97eb-6e268ad95dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def h(A, Theta): \n",
    "    return 1 / (1.0 + np.exp(-1 * z(A, Theta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926755bf-4d46-44f7-9897-a2f8c4238b79",
   "metadata": {},
   "source": [
    "That means that, with **Forward Propagation** we will have: \n",
    "\n",
    "$$\n",
    "A^{(0)} = X \\textrm{ and is } \\mathbb{R}^{3,m} \\\\\n",
    "A^{(1)} = z(A^{(0)}, \\Theta^{(0)}) \\textrm{ and is } \\mathbb{R}^{2, m} (=\\mathbb{R}^{2, 3} * \\mathbb{R}^{3,m})\n",
    "$$\n",
    "\n",
    "Now, after $A^{(1)}$ has been calculated, you need to add a vector of 1s to it so that it goes from being $\\mathbb{R}^{2, m}$ to $\\mathbb{R}^{3, m}$, where the first row $A^{(1)}_0$ is only **ones**. <br>\n",
    "So that now, $A^{(2)}$ will be: \n",
    "\n",
    "$$\n",
    "A^{(2)} = z(A^{(1)}, \\Theta^{(1)}) \\textrm{ and is } \\mathbb{R}^{1, m} (=\\mathbb{R}^{1, 3} * \\mathbb{R}^{3, m})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf988b11-7229-441c-a04e-03f896477202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
